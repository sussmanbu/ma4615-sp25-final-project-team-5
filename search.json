[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This comes from the file about.qmd.\nThis is a website for the final project for MA[46]15 Data Science with R by Team 5. The members of this team are below."
  },
  {
    "objectID": "about.html#chuancheng-xia",
    "href": "about.html#chuancheng-xia",
    "title": "About",
    "section": "Chuancheng Xia",
    "text": "Chuancheng Xia\nChuancheng Xia is a student in math an CS. Github"
  },
  {
    "objectID": "about.html#siyan-li",
    "href": "about.html#siyan-li",
    "title": "About",
    "section": "Siyan Li",
    "text": "Siyan Li\nSiyan is an undergraduate student in Neurobiology and is a student for the course. Github"
  },
  {
    "objectID": "about.html#thomas-laz",
    "href": "about.html#thomas-laz",
    "title": "About",
    "section": "Thomas Laz",
    "text": "Thomas Laz\nThomas is an undergraduate student studying applied mathematics with a minor in public health. Github"
  },
  {
    "objectID": "about.html#dakshesh-kasliwal",
    "href": "about.html#dakshesh-kasliwal",
    "title": "About",
    "section": "Dakshesh Kasliwal",
    "text": "Dakshesh Kasliwal\nDakshesh is an undergraduate student in Questrom concentrating in business analytics and marketing. Github"
  },
  {
    "objectID": "about.html#yunha-oh",
    "href": "about.html#yunha-oh",
    "title": "About",
    "section": "Yunha Oh",
    "text": "Yunha Oh\nYunha is an undergraduate student majoring in Economics and minoring in Statistics. Github \n\nAbout this Template.\nThis is based off of the standard Quarto website template from RStudio (2023.09.0 Build 463)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MA [46]15 Final Project",
    "section": "",
    "text": "Final Project due May 5, 2024 at 11:59pm.\nThis comes from the index.qmd file.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 8\n\n\n\n\n\n\n\n\n\n\n\nApr 30, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 7\n\n\n\n\n\n\n\n\n\n\n\nApr 22, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 6\n\n\n\n\n\n\n\n\n\n\n\nApr 11, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 5\n\n\n\n\n\n\n\n\n\n\n\nApr 7, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 4\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\n\n\n\n\n\n\nBlog post 3\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\n\n\n\n\n\n\nBlog post 2\n\n\n\n\n\n\n\n\n\n\n\nMar 5, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\n\n\n\n\n\n\nBlog Post 1\n\n\n\n\n\n\n\n\n\n\n\nFeb 24, 2025\n\n\nKasliwal, Dakshesh; Laz, Thomas; Li, Siyan; Oh, Yunha; Xia, Chuancheng\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "Analysis",
    "section": "",
    "text": "This comes from the file analysis.qmd."
  },
  {
    "objectID": "analysis.html#introduction",
    "href": "analysis.html#introduction",
    "title": "Analysis",
    "section": "Introduction",
    "text": "Introduction\nEver since the first cases of HIV were detected in the late 1950s and early 1960s, it has been one of the deadliest diseases circulating. While modern medical advancements have turned it from a fatal diagnosis to a chronic condition, access to that medicine isn’t available to everyone.\nNew York City has long been a focal point in the fight against HIV/AIDS, but the burden of this disease is not shared equally. Our project investigates disparities in HIV and AIDS diagnoses across NYC neighborhoods and boroughs between 2010 to 2013 and 2016 to 2021. The data, originally compiled by New York City’s Department of Health and Mental Hygiene, offers a rich foundation for analyzing trends and disparities in diagnosis rates.\nWe focus on answering the following key questions:\nHow do total HIV and AIDS diagnoses differ by race and neighborhood? Are certain demographic groups experiencing disproportionately high rates of infection?\nTo start, it became evident that black people experienced disproportionately higher levels of HIV/AIDS. The following plot displays the number of HIV/AIDS cases compared to the proportion of black residents in an area.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThe graph displays a clear relationship between the proportion of black residents in an area and the number of HIV/AIDS cases. The areas with the lowest proportions of residents generally have the fewest number of cases, although there’s one obvious outlier. This number of cases increases rapidly up to a certain percentage of black residents, when the number of cases doesn’t increase much, but then when the percentage of black residents reaches around 50%, the number of cases begins to rapidly increase again.\nWhen analyzing the data, it became apparent some areas consistently had more HIV/AIDS cases than others. This lead to wanting to analyze what the cause of this trend was. Below is a plot demonstrating this trend.\n\n\n\n\n\n\n\n\n\nAs displayed above, some areas had significantly more cases than others. Noting how earlier it was noticed that areas with higher proportions of black residents had more HIV/AIDS cases, this plot was colored according to each neigborhood’s proportion of black residents. This pattern still emerged, as the areas with the most cases generally have the highest number of cases, although West Queens is an obvious outlier.\nWith the areas typically having the most cases also typically having the highest proportion of black resident, this begs the ultimate question of:\nDo these areas have the most cases because they have the most black people, or do black people have the most cases because they live in these areas?"
  },
  {
    "objectID": "analysis.html#modeling",
    "href": "analysis.html#modeling",
    "title": "Analysis",
    "section": "Modeling",
    "text": "Modeling"
  },
  {
    "objectID": "analysis.html#limitations",
    "href": "analysis.html#limitations",
    "title": "Analysis",
    "section": "Limitations",
    "text": "Limitations\nBoth models have many of the same limitations. A factor that could be considered a limitation is what made the dataset so easy to work with in the beginning, which is that the data was stored according to New York City’s UHF42 neighborhoods. While this allowed for easy storage and data manipulation, it made finding other datasets to join and other variables to add as a predictor rather difficult, as the data had to be stored in a similar format, in order to not compromise the integrity of our model by including fewer data points than neighborhoods they would be applied to. This meant some predictors which may be statistically significant, like drug usage, age and sex demographics, and proportion of LGBTQ residents, couldn’t be added because if this data was available, it wasn’t available at the UHF 42 level. The only time data was added that didn’t have data stored according to UHF42 neighborhoods was for the health insurance rate predictor. This data was stored in UHF34 neighborhoods. The reasons it was still added to the dataset are 34 values was enough for a variable we thought would be very helpful for our model and many of the UHF34 and UHF42 neighborhoods are the exact same; the UHF34 neighborhoods that are different are formed by combining several UHF42 neighborhoods, so some UHF42 neighborhoods had their exact health insurance rates.\nThe next limitation our models have is many of the rates in the dataset are predicted rates generated using a polynomial model. The reason this had to be done is the majority of data stored according to UHF42 neighborhoods was also stored in five-year periods, such as 2017-2021 inclusive, then 2016-2020, 2015-2019, and so on, and giving the average value over that time period. The original HIV dataset was stored year-by-year, not according to these five-year periods, so to get values for our predictors, the middle year of each five year time period was taken and the average value over the corresponding five-year period was assigned to that middle year. This supplied data for every year in the original dataset, except 2020 and 2021, so a polynomial model was used to predict the values for those two years. This process was used for every predictor variable stored according to this format.\nThe final major limitation of these models is the main assumption of every Poisson model, which is that the mean equals the variance. It makes this assumption due to the form of the distribution. If the data being modeled doesn’t fit this distribution well, even if it’s a count variable, then using a Poisson model will result in overdispersion, although this didn’t seem to be a glaring issue in this particular analysis."
  },
  {
    "objectID": "dataset/modeling_code.html",
    "href": "dataset/modeling_code.html",
    "title": "Modeling Code",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npov &lt;- read_csv(here::here(\"dataset\",\"NYC EH Data Portal - Neighborhood poverty (filtered) (1).csv\"), show_col_types = FALSE)\n\nhiv_clean &lt;- read_rds(\"https://sussmanbu.github.io/ma4615-sp25-final-project-team-5/dataset_for_shiny/hiv_clean.rds\")\n\npov &lt;- read_csv(here::here(\"dataset\",\"NYC EH Data Portal - Neighborhood poverty (filtered) (1).csv\"))\n\nRows: 517 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): TimePeriod, GeoTypeDesc, Borough, Geography, Area\ndbl (4): GeoID, GeoRank, BoroID, Percent\nnum (1): Number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npov_c &lt;- pov |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\npov_by_neighborhood &lt;- pov_c |&gt;\n  filter(GeoTypeDesc == \"UHF 42\") |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Poverty Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\n\nrace_total &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Race and ethnicity (filtered) (1).csv\"))\n\nRows: 528 Columns: 14\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): TimePeriod, GeoTypeDesc, BoroID, Borough, Geography, Area\ndbl (7): GeoID, GeoRank, Asian alone (percent), Black alone (percent), Hispa...\nnum (1): Total population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrt &lt;- race_total |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\n\nasian_uhf &lt;- rt |&gt;\n  filter(GeoTypeDesc == \"UHF 42\") |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(`Asian alone (percent)` ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, asian_prop = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    \"Neighborhood (U.H.F)\" = Geography,\n    YEAR = midpoint\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\nblack_uhf &lt;- rt |&gt;\n  filter(GeoTypeDesc == \"UHF 42\") |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(`Black alone (percent)` ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, black_prop = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    \"Neighborhood (U.H.F)\" = Geography,\n    YEAR = midpoint\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\nhispanic_uhf &lt;- rt |&gt;\n  filter(GeoTypeDesc == \"UHF 42\") |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(`Hispanic alone (percent)` ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, hispanic_prop = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    \"Neighborhood (U.H.F)\" = Geography,\n    YEAR = midpoint\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\nwhite_uhf &lt;- rt |&gt;\n  filter(GeoTypeDesc == \"UHF 42\") |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(`White alone (percent)` ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, white_prop = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    \"Neighborhood (U.H.F)\" = Geography,\n    YEAR = midpoint\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\n\ngrad &lt;- read_csv(here::here(\"dataset\",\"NYC EH Data Portal - Graduated high school (filtered).csv\"))\n\nRows: 462 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): TimePeriod, GeoTypeDesc, Borough, Geography, Area\ndbl (4): GeoID, GeoRank, BoroID, Percent\nnum (1): Number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ngrad_f &lt;- grad |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\ngrad_by_neighborhood &lt;- grad_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated High School Graduation Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  ) |&gt;\n  mutate(`Estimated Non-High School Graduation Rate` = 100 - `Estimated High School Graduation Rate`) |&gt;\n  select(-`Estimated High School Graduation Rate`)\n\n\nunemp &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Unemployment (filtered).csv\"))\n\nRows: 462 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): TimePeriod, GeoTypeDesc, Borough, Geography, Area\ndbl (4): GeoID, GeoRank, BoroID, Percent\nnum (1): Number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nunemp_f &lt;- unemp |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\nunemp_by_neighborhood &lt;- unemp_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Unemployment Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\n\nrb &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Rent-burdened households (filtered).csv\"))\n\nRows: 462 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): TimePeriod, GeoTypeDesc, Borough, Geography, Area\ndbl (4): GeoID, GeoRank, BoroID, Percent\nnum (1): Number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nrb_f &lt;- rb |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\nrb_by_uhf &lt;- rb_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Rent-Burdened Household Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\n\nooh &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Owner-occupied homes (filtered).csv\"))\n\nRows: 462 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): TimePeriod, GeoTypeDesc, Borough, Geography, Area\ndbl (4): GeoID, GeoRank, BoroID, Percent\nnum (1): Number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nooh_f &lt;- ooh |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\nooh_by_uhf &lt;- ooh_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Owner-Occupied Home Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  ) |&gt;\n  mutate(`Estimated Non-Owner-Occupied Home Rate` = 100 - `Estimated Owner-Occupied Home Rate`) |&gt;\n  select(-`Estimated Owner-Occupied Home Rate`)\n\n\ncpov &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Child poverty (under age 5) (filtered).csv\"))\n\nRows: 462 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): TimePeriod, GeoTypeDesc, Borough, Geography, Area\ndbl (4): GeoID, GeoRank, BoroID, Percent\nnum (1): Number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncpov_f &lt;- cpov |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\ncpov_by_uhf &lt;- cpov_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Child Poverty Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\n\nasth &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Asthma hospitalizations (adults) (filtered).csv\"))\n\nRows: 672 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): GeoTypeDesc, Borough, Geography, Area, Number, Estimated annual rat...\ndbl (4): TimePeriod, GeoID, GeoRank, BoroID\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nasth_f &lt;- asth |&gt;\n  mutate(`Age-adjusted rate per 10,000` = as.numeric(gsub(\"\\\\*\", \"\", `Age-adjusted rate per 10,000`))) |&gt;\n  select(-`Estimated annual rate per 10,000`)\n\nasth_uhf &lt;- asth_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(`Age-adjusted rate per 10,000` ~ poly(TimePeriod, 2), data = .x)),\n    newdata = list(tibble(TimePeriod = 2005:2022)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!TimePeriod %in% c(2005, 2006, 2007, 2008, 2009, 2014, 2015, 2022)) |&gt;\n  rename(\n    YEAR = TimePeriod,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Asthma Hospitalization Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\n\nhc &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Household crowding (filtered) (1).csv\"))\n\nRows: 462 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): TimePeriod, GeoTypeDesc, Borough, Geography, Area\ndbl (4): GeoID, GeoRank, BoroID, Percent\nnum (1): Number\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhc_f &lt;- hc |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\nhc_uhf &lt;- hc_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Crowded Household Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\n\nhi &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Health insurance (adults) (filtered)(1).csv\"))\n\nRows: 320 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): GeoTypeDesc, BoroID, Borough, Geography, Area, Number, Percent\ndbl (3): TimePeriod, GeoID, GeoRank\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nmap_uhf &lt;- read_csv(here::here(\"dataset\", \"UHF34_to_UHF42 .csv\")) |&gt;\n  mutate(`Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \"Staple - St. George\", \"Stapleton - St. George\"))\n\nRows: 42 Columns: 2\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (2): Geography, Neighborhood (U.H.F)\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhi_f &lt;- hi |&gt;\n  filter(GeoTypeDesc == \"UHF 34\") |&gt;\n  rename(YEAR = TimePeriod) |&gt;\n  select(YEAR, GeoTypeDesc, Geography, Percent) |&gt;\n  mutate(\n    Percent = str_remove_all(Percent, \"\\\\*|\\\\s*\\\\(.*\\\\)\"),\n    Percent = as.numeric(Percent)\n  ) |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(`Percent` ~ poly(YEAR, 2), data = .x)),\n    newdata = list(tibble(YEAR = 2010:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!YEAR %in% c(2014, 2015)) |&gt;\n  mutate(`Estimated Non-Health Insurance Rate` = 100 - `estimated_rate`) |&gt;\n  select(-`estimated_rate`)\n\nhi_uhf &lt;- hi_f |&gt;\n  left_join(map_uhf, by = \"Geography\") |&gt;\n  ungroup() |&gt;\n  select(-Geography)\n\nWarning in left_join(hi_f, map_uhf, by = \"Geography\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 41 of `x` matches multiple rows in `y`.\nℹ Row 1 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\n\n\nhiv_filt &lt;- hiv_clean |&gt;\n  filter(`Neighborhood (U.H.F)` != \"All\", `RACE/ETHNICITY` == \"All\", SEX == \"All\")\n\njoin1 &lt;- hiv_filt |&gt;\n  left_join(pov_by_neighborhood, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin2 &lt;- join1 |&gt;\n  left_join(asian_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin3 &lt;- join2 |&gt;\n  left_join(black_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin4 &lt;- join3 |&gt;\n  left_join(hispanic_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin5 &lt;- join4 |&gt;\n  left_join(white_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin6 &lt;- join5 |&gt;\n  left_join(grad_by_neighborhood, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin7 &lt;- join6 |&gt;\n  left_join(unemp_by_neighborhood, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin8 &lt;- join7 |&gt;\n  left_join(rb_by_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin9 &lt;- join8 |&gt;\n  left_join(ooh_by_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin10 &lt;- join9 |&gt;\n  left_join(cpov_by_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin11 &lt;- join10 |&gt;\n  left_join(asth_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin12 &lt;- join11 |&gt;\n  left_join(hc_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\njoin13 &lt;- join12 |&gt;\n  left_join(hi_uhf, by = c(\"YEAR\", \"Neighborhood (U.H.F)\"))\n\n\nmod_formula &lt;- `TOTAL NUMBER OF CONCURRENT HIV/AIDS DIAGNOSES` ~ `YEAR` + `Estimated Poverty Rate` + `Estimated Non-High School Graduation Rate` + `Estimated Unemployment Rate` + `Estimated Rent-Burdened Household Rate` + `Estimated Non-Owner-Occupied Home Rate` + `Estimated Child Poverty Rate` + `Estimated Asthma Hospitalization Rate` + `Estimated Crowded Household Rate` + `Estimated Non-Health Insurance Rate` + `black_prop`\n\nmod2_formula &lt;- `TOTAL NUMBER OF CONCURRENT HIV/AIDS DIAGNOSES` ~ `YEAR` + `Neighborhood (U.H.F)` + `Estimated Poverty Rate` + `Estimated Non-High School Graduation Rate` + `Estimated Unemployment Rate` + `Estimated Rent-Burdened Household Rate` + `Estimated Non-Owner-Occupied Home Rate` + `Estimated Child Poverty Rate` + `Estimated Asthma Hospitalization Rate` + `Estimated Crowded Household Rate` + `Estimated Non-Health Insurance Rate` + `black_prop`\n\nmod1 &lt;- glm(mod_formula, family = poisson, data = join13)\n\nmod2 &lt;- glm(mod2_formula, family = poisson, data = join13)\n\nsummary(mod1)\n\n\nCall:\nglm(formula = mod_formula, family = poisson, data = join13)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-4.8669  -1.4967  -0.3489   0.8271   5.8842  \n\nCoefficients:\n                                              Estimate Std. Error z value\n(Intercept)                                 72.7230955 14.6311501   4.970\nYEAR                                        -0.0374327  0.0072747  -5.146\n`Estimated Poverty Rate`                    -0.0670164  0.0094439  -7.096\n`Estimated Non-High School Graduation Rate`  0.0105715  0.0051958   2.035\n`Estimated Unemployment Rate`               -0.0655507  0.0109724  -5.974\n`Estimated Rent-Burdened Household Rate`     0.0599263  0.0058008  10.331\n`Estimated Non-Owner-Occupied Home Rate`     0.0396097  0.0019551  20.260\n`Estimated Child Poverty Rate`               0.0003831  0.0044550   0.086\n`Estimated Asthma Hospitalization Rate`      0.0105366  0.0023596   4.465\n`Estimated Crowded Household Rate`          -0.0215757  0.0076886  -2.806\n`Estimated Non-Health Insurance Rate`        0.0252673  0.0030549   8.271\nblack_prop                                   0.0188863  0.0009193  20.544\n                                            Pr(&gt;|z|)    \n(Intercept)                                 6.68e-07 ***\nYEAR                                        2.67e-07 ***\n`Estimated Poverty Rate`                    1.28e-12 ***\n`Estimated Non-High School Graduation Rate`  0.04189 *  \n`Estimated Unemployment Rate`               2.31e-09 ***\n`Estimated Rent-Burdened Household Rate`     &lt; 2e-16 ***\n`Estimated Non-Owner-Occupied Home Rate`     &lt; 2e-16 ***\n`Estimated Child Poverty Rate`               0.93147    \n`Estimated Asthma Hospitalization Rate`     7.99e-06 ***\n`Estimated Crowded Household Rate`           0.00501 ** \n`Estimated Non-Health Insurance Rate`        &lt; 2e-16 ***\nblack_prop                                   &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 3398.6  on 417  degrees of freedom\nResidual deviance: 1324.2  on 406  degrees of freedom\nAIC: 2871.1\n\nNumber of Fisher Scoring iterations: 5\n\nAIC(mod1)\n\n[1] 2871.11\n\nBIC(mod1)\n\n[1] 2919.535\n\nlogLik(mod1)\n\n'log Lik.' -1423.555 (df=12)\n\npearson_resid &lt;- sum(residuals(mod1, type = \"pearson\")^2)\npearson_resid\n\n[1] 1342.655\n\n\n\nlibrary(broom)\nlibrary(gt)\n\ntidy(mod1) |&gt;\n  mutate(\n    estimate = exp(estimate),\n    estimate = round(estimate, 3),\n    std.error = round(std.error, 3),\n    p.value = round(p.value, 4)\n  ) |&gt;\n  select(term, estimate, std.error, p.value) |&gt;\n  rename(\n    Predictor = term,\n    `Rate Ratio` = estimate,\n    `Std. Error` = std.error,\n    `P-Value` = p.value\n  ) |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Exponentiated Coefficients from Poisson Regression Model\"\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  )\n\n\n\n\n\n\n\nExponentiated Coefficients from Poisson Regression Model\n\n\nPredictor\nRate Ratio\nStd. Error\nP-Value\n\n\n\n\n(Intercept)\n3.830355e+31\n14.631\n0.0000\n\n\nYEAR\n9.630000e-01\n0.007\n0.0000\n\n\n`Estimated Poverty Rate`\n9.350000e-01\n0.009\n0.0000\n\n\n`Estimated Non-High School Graduation Rate`\n1.011000e+00\n0.005\n0.0419\n\n\n`Estimated Unemployment Rate`\n9.370000e-01\n0.011\n0.0000\n\n\n`Estimated Rent-Burdened Household Rate`\n1.062000e+00\n0.006\n0.0000\n\n\n`Estimated Non-Owner-Occupied Home Rate`\n1.040000e+00\n0.002\n0.0000\n\n\n`Estimated Child Poverty Rate`\n1.000000e+00\n0.004\n0.9315\n\n\n`Estimated Asthma Hospitalization Rate`\n1.011000e+00\n0.002\n0.0000\n\n\n`Estimated Crowded Household Rate`\n9.790000e-01\n0.008\n0.0050\n\n\n`Estimated Non-Health Insurance Rate`\n1.026000e+00\n0.003\n0.0000\n\n\nblack_prop\n1.019000e+00\n0.001\n0.0000\n\n\n\n\n\n\n\n\nfit_stats &lt;- data.frame(\n  Statistic = c(\"Deviance\", \"AIC\", \"BIC\", \"Log-Likelihood\", \"Pearson Chi-Square\"),\n  Value = c(deviance(mod1), AIC(mod1), BIC(mod1), logLik(mod1), pearson_resid)\n)\n\nfit_stats |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Fit Statistics of the Poisson Regression Model\"\n  ) |&gt;\n  fmt_number(\n    columns = vars(Value),\n    decimals = 2\n  )\n\nWarning: Since gt v0.3.0, `columns = vars(...)` has been deprecated.\n• Please use `columns = c(...)` instead.\n\n\n\n\n\n\n\n\nFit Statistics of the Poisson Regression Model\n\n\nStatistic\nValue\n\n\n\n\nDeviance\n1,324.25\n\n\nAIC\n2,871.11\n\n\nBIC\n2,919.54\n\n\nLog-Likelihood\n−1,423.55\n\n\nPearson Chi-Square\n1,342.66"
  },
  {
    "objectID": "posts/2025-04-30-blog-post-8/blog-post-8.html",
    "href": "posts/2025-04-30-blog-post-8/blog-post-8.html",
    "title": "Blog Post 8",
    "section": "",
    "text": "For this week’s blog post, we continued working on the final analytical aspects of our project, and began the process of making our website aesthetically appealing and presenting the data in an understandable and streamlined way. Below are answers to the three major questions for this blog post.\nHow are you continuing your exploratory data analysis?\nThis week, we finally got our interactive published using shinyapps.io\nWe also continued adding predictors to our main dataset before constructing the final statistical model. So far, we’ve added an estimated poverty rate and estimated proportions of each major race in each neighborhood.\nWe decided to model our dataset after the dataset from Homework 8. For each year, we took each borough and each UHF 42 neighborhood and filtered to include the entries where both race and sex are all. This will allow us to have one row of observation, easing the modeling process. For each row, we will have a predictor, including the ones mentioned above, and we hope to add health insurance rate, a gender proportion, age proportion, high school graduation rate, crowded housing rate, and incarceration rates.\nWe’re also continuing to make maps displaying this information that we might use in our Big Picture page. These will be done using the UHF shapefiles we used in blog post 6.\nWhat is your thesis?\nBased on the findings we’ve made over the course of this project, our thesis will be along the lines of: “In New York City, Hispanic, and especially black people, have increased rates of contracting HIV, compared to the other demographics in New York City.”\nHow do you plan to polish your visualizations and tables?\nWe’ve been satisfied with the use of shapefiles and using a continuous gradient to color in the neighborhoods. Using the gt package to create tables is something we’re also considering. We’ve already begun adding our own images to the website.\nThe biggest way we’ve thought about visualization is how we can lead the readers in a logical direction with our graphs. We want to guide readers to asking themselves certain questions and then having the next graphs answer those questions and create new ones, until we’ve told the entire story. As we continue to finalize the exact path we want to take readers down, we’ll use other methods of visualization to enhance the experience."
  },
  {
    "objectID": "posts/2025-04-11-blog-post-6/blog-post-6.html",
    "href": "posts/2025-04-11-blog-post-6/blog-post-6.html",
    "title": "Blog Post 6",
    "section": "",
    "text": "For this week’s blog post, we devoted most of our effort into brainstorming how we’re going to present the data on our website. We tried to put ourselves in the place of someone who has no idea what we’re analyzing and determine the best way to make our findings comprehensible to this person. We decided the best way to begin was by displaying a series of basic plots displaying the most basic aspects of our data. For example, below are two plots. One displays the total number of HIV cases in each borough and the other displays the total number of HIV cases for each race. This seemed like the first logical step because when someone reads that we’re analyzing HIV data, the first thing they probably think is, “How many cases are there?”.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow that we made these basic plots, we decided the next step is to identify any trends and do slightly below surface-level analysis on them. We made other plots we plan to include on our final website and one trend we noticed is that Brooklyn always had the most total cases for boroughs, and black people always had the most total cases for race. When someone sees these raw totals, the first thing we anticipate them wondering is, “Well, is this just because there are more people in Brooklyn than the other boroughs and more black people than any other race?”. To assuage these concerns, we move to slightly below surface-level analysis, which is adjusting for population. Below are two plots. They are boxplots displaying the number of HIV cases per 100,000 people for each borough and race.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# A tibble: 10 × 1\n    YEAR\n   &lt;dbl&gt;\n 1  2021\n 2  2020\n 3  2019\n 4  2018\n 5  2017\n 6  2016\n 7  2013\n 8  2012\n 9  2011\n10  2010\n\n\nThese plots should answer that basic question of normalizing population. For example, in the boroughs plot, we see the question about total population did have an impact on Brooklyn having the most total HIV cases, as the boxplots display, it has the third highest average number of HIV cases per 100,000, despite having the most total HIV cases, indicating that if all boroughs had the same population, Brooklyn might not have the most total cases. When it comes to race, however, we see population had little-to-no affect; black people had the most total cases and the hgihest number of average cases per 100,000 people.\nThe next question we anticipate people wondering is, “Do the boroughs with more cases have more black and Hispanic people than boroughs with fewer cases?”. Since black and Hispanic people have more cases on average than white and Asian/Pacific Islanders, it seems logical that the boroughs with more cases have more of those demographics. Below are two plots. Each is a map of New York City, broken down into 42 smaller neighborhoods, based on the locations served by UHF hospitals. The first displays areas based on the proportion of black residents, and the second displays the proportion of Hispanic residents in each neighborhood. The data on proportions came from New York City’s official Environment and Health data portal, one of the datasets we wrote about in our previous blog post and the shapefiles were downloaded online.\n\n\nLinking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple feature collection with 43 features and 3 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 913176 ymin: 120122 xmax: 1067382 ymax: 272844\nProjected CRS: Lambert_Conformal_Conic\nFirst 10 features:\n    id Black alone (percent) Hispanic alone (percent)\n1    0                    NA                       NA\n2  101                  11.3                     45.6\n3  102                  56.6                     27.7\n4  103                  20.2                     66.8\n5  104                  19.4                     53.3\n6  105                  27.1                     67.0\n7  106                  33.5                     61.0\n8  107                  26.4                     69.8\n9  201                   3.4                     21.9\n10 202                  12.7                     14.8\n                         geometry\n1  MULTIPOLYGON (((945656 1323...\n2  MULTIPOLYGON (((1012516 256...\n3  MULTIPOLYGON (((1030514 251...\n4  MULTIPOLYGON (((1020336 251...\n5  MULTIPOLYGON (((1030534 251...\n6  MULTIPOLYGON (((1005404 247...\n7  MULTIPOLYGON (((1012320 241...\n8  MULTIPOLYGON (((1019508 231...\n9  MULTIPOLYGON (((1005154 200...\n10 MULTIPOLYGON (((990948 1784...\n\n\n    id Black alone (percent) Hispanic alone (percent)\n1    0                    NA                       NA\n2  101                  11.3                     45.6\n3  102                  56.6                     27.7\n4  103                  20.2                     66.8\n5  104                  19.4                     53.3\n6  105                  27.1                     67.0\n7  106                  33.5                     61.0\n8  107                  26.4                     69.8\n9  201                   3.4                     21.9\n10 202                  12.7                     14.8\n11 203                  57.5                     14.1\n12 204                  50.5                     37.7\n13 205                   3.0                     41.9\n14 206                   4.2                     13.0\n15 207                  64.5                     10.2\n16 208                  63.3                      9.3\n17 209                   2.2                     16.7\n18 210                   6.5                     12.0\n19 211                  24.1                     39.6\n20 301                  10.6                     63.9\n21 302                  47.1                     25.3\n22 303                  28.7                     45.2\n23 304                   5.8                     15.1\n24 305                   2.8                      9.1\n25 306                   5.2                     16.6\n26 307                   4.4                     10.1\n27 308                   2.5                      8.5\n28 309                   6.6                     20.4\n29 310                   5.9                      8.7\n30 401                   4.9                     23.9\n31 402                   4.6                     51.6\n32 403                   1.7                     17.9\n33 404                   2.8                     13.9\n34 405                   2.3                     29.2\n35 406                   7.7                     17.8\n36 407                   9.9                     33.9\n37 408                  48.6                     17.2\n38 409                  41.5                     14.3\n39 410                  34.4                     23.3\n40 501                  24.7                     35.6\n41 502                  16.2                     20.9\n42 503                   3.7                     15.1\n43 504                   1.5                     12.3\n                         geometry\n1  MULTIPOLYGON (((945656 1323...\n2  MULTIPOLYGON (((1012516 256...\n3  MULTIPOLYGON (((1030514 251...\n4  MULTIPOLYGON (((1020336 251...\n5  MULTIPOLYGON (((1030534 251...\n6  MULTIPOLYGON (((1005404 247...\n7  MULTIPOLYGON (((1012320 241...\n8  MULTIPOLYGON (((1019508 231...\n9  MULTIPOLYGON (((1005154 200...\n10 MULTIPOLYGON (((990948 1784...\n11 MULTIPOLYGON (((1001656 180...\n12 MULTIPOLYGON (((1014886 176...\n13 MULTIPOLYGON (((984104 1711...\n14 MULTIPOLYGON (((991748 1610...\n15 MULTIPOLYGON (((994620 1703...\n16 MULTIPOLYGON (((1003482 151...\n17 MULTIPOLYGON (((987734 1507...\n18 MULTIPOLYGON (((1004698 152...\n19 MULTIPOLYGON (((1011406 191...\n20 MULTIPOLYGON (((995374 2381...\n21 MULTIPOLYGON (((995304 2324...\n22 MULTIPOLYGON (((1004316 223...\n23 MULTIPOLYGON (((986050 2208...\n24 MULTIPOLYGON (((995736 2156...\n25 MULTIPOLYGON (((981976 2096...\n26 MULTIPOLYGON (((987768 2084...\n27 MULTIPOLYGON (((982158 1999...\n28 MULTIPOLYGON (((985342 1976...\n29 MULTIPOLYGON (((981154 1948...\n30 MULTIPOLYGON (((1000104 208...\n31 MULTIPOLYGON (((1019274 227...\n32 MULTIPOLYGON (((1032688 209...\n33 MULTIPOLYGON (((1054996 206...\n34 MULTIPOLYGON (((1023838 194...\n35 MULTIPOLYGON (((1045958 202...\n36 MULTIPOLYGON (((1023868 176...\n37 MULTIPOLYGON (((1050504 185...\n38 MULTIPOLYGON (((1055226 171...\n39 MULTIPOLYGON (((1034042 156...\n40 MULTIPOLYGON (((934682 1634...\n41 MULTIPOLYGON (((952606 1507...\n42 MULTIPOLYGON (((951532 1573...\n43 MULTIPOLYGON (((919410 1219...\n\n\nWe anticipate that readers will have their next concerned assuaged by this map. In case anyone isn’t familiar with NYC’s geography, the western island is Staten Island, the southwestern portion of the city is Brooklyn, the southeastern portion is Queens, the northwestern portion is Manhattan, and the northeastern portion is the Bronx. As displayed by the maps, Brooklyn, the Bronx, and Manhattan, the areas with the highest total and average number of cases, have the most black and Hispanic residents, while Queens and Staten Island, which have the fewest cases, have fewer black and Hispanic residents.\nThe next question we anticipate readers to ask is why do areas with more black and Hispanic residents have more HIV cases and this is what we will continue to analyze for the duration of the semester.\n\nlibrary(sf)\nlibrary(readr)\nlibrary(here)\n\nshape &lt;- st_read(here::here(\"dataset\", \"NYC_geography-master\", \"NYC_geography-master\", \"uhf34_shapefiles\", \"CHS_UHF_34_DOHMH_2004.shp\"), quiet = TRUE)\n\nshape &lt;- shape |&gt; rename(GeoID=UHFtxt) |&gt; select(GeoID) |&gt; filter(GeoID!=0)\n\ninsurance &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Health insurance (adults) (filtered)(1).csv\"),\n                 col_types = cols(GeoID = col_character()))\n\ninsurance &lt;- insurance |&gt; mutate(percent_only = str_extract(Percent, \"^[0-9.]+\"))\n\ninsurance_uhf &lt;- insurance |&gt; filter(!(Geography %in% c(\"New York City\", \"Bronx\", \"Brooklyn\", \"Manhattan\", \"Queens\", \"Staten Island\")))\n\n##################################################################################################\n\ninsurance_uhf_filter_2021&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2021\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2020&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2020\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2019&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2019\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2018&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2018\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2017&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2017\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2016&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2016\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2013&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2013\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2012&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2012\")|&gt;select(GeoID, percent_only)\n\n##################################################################################################\n\njoined_2021 &lt;- shape |&gt; left_join(insurance_uhf_filter_2021, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2020 &lt;- shape |&gt; left_join(insurance_uhf_filter_2020, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2019 &lt;- shape |&gt; left_join(insurance_uhf_filter_2019, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2018 &lt;- shape |&gt; left_join(insurance_uhf_filter_2018, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2017 &lt;- shape |&gt; left_join(insurance_uhf_filter_2017, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2016 &lt;- shape |&gt; left_join(insurance_uhf_filter_2016, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2013 &lt;- shape |&gt; left_join(insurance_uhf_filter_2012, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2012 &lt;- shape |&gt; left_join(insurance_uhf_filter_2012, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\n##################################################################################################\n\nall_data &lt;- bind_rows(\n  joined_2021,\n  joined_2020,\n  joined_2019,\n  joined_2018,\n  joined_2017,\n  joined_2016,\n  joined_2013,\n  joined_2012\n)\n\n##################################################################################################\n\n# Global min and max for color scale\nglobal_min &lt;- min(all_data$percent_only, na.rm = TRUE)\nglobal_max &lt;- max(all_data$percent_only, na.rm = TRUE)\n\n##################################################################################################\n\nggplot() +\n  geom_sf(data = joined_2021, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2021\")\n\nggplot() +\n  geom_sf(data = joined_2020, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2020\")\n\nggplot() +\n  geom_sf(data = joined_2019, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2019\")\n\nggplot() +\n  geom_sf(data = joined_2018, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2018\")\n\nggplot() +\n  geom_sf(data = joined_2017, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2017\")\n\nggplot() +\n  geom_sf(data = joined_2016, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2016\")\n\nggplot() +\n  geom_sf(data = joined_2013, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2013\")\n\nggplot() +\n  geom_sf(data = joined_2012, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2012\")"
  },
  {
    "objectID": "posts/2025-03-28-blog-post-4/blog-post-4.html",
    "href": "posts/2025-03-28-blog-post-4/blog-post-4.html",
    "title": "Blog Post 4",
    "section": "",
    "text": "We began to explore several trends we noticed during our data analysis more thoroughly.\nFrom “Line Charts: Trends Over Time (data.qmd)”, the increase is observed only in the Asian/Pacific Islander category, even though a general reduction in HIV diagnoses rates over time across all racial/ethnic groups.\n##Comparing “Total Number of HIV Diagnoses” by Sex for Asian/Pacific Islanders\n\nsuppressPackageStartupMessages(library(tidyverse))\nlibrary(readr)\nlibrary(here)\n\nhere() starts at /home/tvlaz/MA415/ma4615-sp25-final-project-team-5\n\ndf &lt;- read_rds(here::here(\"dataset\", \"hiv_clean.rds\"))\n\n\nggplot(df, aes(x = SEX, y = as.numeric(`TOTAL NUMBER OF HIV DIAGNOSES`), fill = SEX)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Total HIV Diagnoses for Asian/Pacific Islanders by Sex\",\n       x = \"Sex\",\n       y = \"Total Number of HIV Diagnoses\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nThe bar graph clearly indicates a significant gender disparity in HIV diagnoses among Asian/Pacific Islanders, with males accounting for a substantially higher number of cases compared to females. The number of diagnoses among males is several times higher than that among females, highlighting a pronounced vulnerability or increased risk exposure for males in this population.\n##Line Graph of HIV Diagnoses Rates per 100,000 Population Over Years by Sex\n\nggplot(df, aes(x = YEAR, y = as.numeric(`HIV DIAGNOSES PER 100,000 POPULATION`), color = SEX)) +\n  geom_line(linewidth = 1.2) +\n  geom_point(size = 3) +\n  labs(title = \"HIV Diagnoses Rates (per 100,000) for Asian/Pacific Islanders by Sex\",\n       x = \"Year\",\n       y = \"HIV Diagnoses per 100,000 Population\") +\n  theme_minimal() +\n  scale_x_continuous(breaks = unique(df$YEAR))\n\n\n\n\n\n\n\n\nThe rate of HIV diagnoses for males (blue dots) is consistently higher than for females (green dots) across all years. Noticeably high spikes occur, especially around 2010-2013 and again in 2017-2018.\nFor statistical modeling, we will need to do two types of modeling, depending on the variable(s) we want to analyze. For example, some of our variables, like “Total Number of HIV Diagnoses,” are count variables, making Poisson regression the best choice for modeling. For other variables, like “HIV Diagnoses Per 100,000 Population,” we can do linear regression, since these are continuous variables. Below is the preliminary statistical analysis exploring the relationship between “Total Number of HIV Diagnoses” and “Race/Ethnicity,” using “White” as the reference variable. As stated above, because “Total Number of HIV Diagnoses” is a count variable, it fits best with a Poisson model.\n\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(tidymodels))\n\nhiv_clean &lt;- readRDS(here::here(\"dataset\", \"hiv_clean.rds\")) |&gt;\n  filter(!`RACE/ETHNICITY` %in% c(\"All\", \"Unknown\", \"Other/Unknown\"))\n\nsplit &lt;- initial_split(hiv_clean, prop = 0.8)\ntraining &lt;- training(split)\ntraining$`RACE/ETHNICITY` &lt;- factor(training$`RACE/ETHNICITY`)\ntraining$`RACE/ETHNICITY` &lt;- relevel(training$`RACE/ETHNICITY`, ref = \"White\")\n\nmod &lt;- glm(`TOTAL NUMBER OF HIV DIAGNOSES` ~ `RACE/ETHNICITY`, family = poisson, training)\nsummary(mod)\n\n\nCall:\nglm(formula = `TOTAL NUMBER OF HIV DIAGNOSES` ~ `RACE/ETHNICITY`, \n    family = poisson, data = training)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-8.069  -4.682  -2.420  -0.275  84.195  \n\nCoefficients:\n                                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                             2.39442    0.01096  218.55   &lt;2e-16 ***\n`RACE/ETHNICITY`Asian/Pacific Islander -0.67104    0.01999  -33.56   &lt;2e-16 ***\n`RACE/ETHNICITY`Black                   1.08848    0.01247   87.25   &lt;2e-16 ***\n`RACE/ETHNICITY`Hispanic                0.95673    0.01264   75.70   &lt;2e-16 ***\n`RACE/ETHNICITY`Multiracial            -4.19005    0.15289  -27.41   &lt;2e-16 ***\n`RACE/ETHNICITY`Native American        -7.25423    0.70664  -10.27   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 219052  on 3660  degrees of freedom\nResidual deviance: 178275  on 3655  degrees of freedom\nAIC: 189073\n\nNumber of Fisher Scoring iterations: 6\n\n\nUsing the estimates, the rate ratio, or how much more likely one group is to have an HIV diagnosis compared to the reference group, which is white people in this case, can be calculated. Asian/Pacific Islanders have an approximate rate ratio of e^(-0.73989) ≈ 0.477. Asian/Pacific Islanders have 0.477 times as many, or approximately 52.3% fewer, HIV diagnoses as white people. For black people, the rate ratio is e^(1.03738) ≈ 2.82, meaning they have approximately 2.82 times as many, or 282% more diagnoses than white people. For Hispanic people, the rate ratio is approximately 2.48, meaning they have 2.48 times as many cases as white people. For multiracial people, the rate ratio is 0.017, meaning they have about 98.3% fewer cases than white people. Finally, for Native Americans, the rate ratio is 0.00073, meaning they have about 99.93% fewer cases than white people. Every z-value is &gt; |10|, meaning indicating race has a very strong correlation with HIV diagnoses, which is confirmed by the p-values all being &lt;2e-16, indicating statistical significance.\nA point of concern is with the deviance residuals and potential overdispersion. The median is negative, indicating the model tended to overestimate the number of HIV diagnoses; however, the max is 70.741, meaning the model grossly underestimated the number of cases at some point. Combining this with a minimum of -7.842 suggests some observations poorly fit the model, indicating potential overdispersion of the dataset. Checking for overdispersion can be done by dividing the residual deviance by the degrees of freedom, which in our case = 159079/3655 ≈ 43.52, confirming the suspicion of overdispersion. In future analysis, changing the model to better account for this overdispersion will be done, in order to achieve the best estimates possible. Likely, this will involve using a negative binomial distribution, which allows the variance to be greater than the mean, unlike the Poisson distribution, which assumes the mean and variance are equal."
  },
  {
    "objectID": "posts/2025-03-05-blog-post-2/blog-post-2.html",
    "href": "posts/2025-03-05-blog-post-2/blog-post-2.html",
    "title": "Blog post 2",
    "section": "",
    "text": "We chose to analyze the dataset about HIV cases in New York City.\n\nData Background\nWhere does the data come from? Who collected it? Why was it collected? Are you able to find the data from the original source?\nThe data originates from the New York City Department of Health and Mental Hygiene (NYC DOHMH), which collected and compiled information on new HIV and AIDS diagnoses reported through March 31, 2021. Specifically, this dataset covers cases diagnosed from calendar years 2016 through 2020. The data were collected to monitor trends in HIV and AIDS diagnoses, enabling public health officials to track disease patterns, guide prevention and treatment strategies, and identify disparities across different neighborhoods and demographic groups within NYC. Cases are stratified by United Hospital Fund (UHF) neighborhoods, sex, and race/ethnicity, allowing for targeted public health responses. The original dataset can typically be obtained directly from the NYC DOHMH or accessed through official public health data portals maintained by New York City.\nAre there any issues you can see with how the data was collected? What is the sample population? Are there reasons to think the sample is biased in some way?\nThe sample population originally includes 8,976 observations. After removing observations that had null entries, the sample size decreased to 7,062. The dataset should be highly accurate, given that the data was collected by a government organization. Additionally, providers and labs are legally required to report any new diagnoses of HIV and AIDS. One way the sample could be biased is that there could be people who don’t get their HIV/AIDS diagnosed, and therefore they wouldn’t be represented in this dataset. This could be a problem if there are a large number of people not reporting their symptoms, and if the people in this group share similar characteristics and/or demographics.\n\n\nData for Equity\nGiven this is a highly sensitive dataset, it is important to be mindful and intentional when collecting and analyzing data. When looking at the instrumentation of the data, it is important to keep beneficence in mind and “Minimize the amount of personally identifiable information collected.” In this instance, NYC DOHMH asked for the respondent’s neighborhood, which is highly granular and potentially sensitive data. To counteract any risks of re-identification, DOHMH doesn’t ask for many other significant demographics, only “borough”, “race/sex”, and “ethnicity”. Additionally, DOHMH lists that one of the reasons for “N/A” cells in the dataset is cell suppression. According to NCES.ed.gov, one of the benefits of cell suppression is “protecting frequency data in tabular form”. However, as mentioned before, the N/A observations do lower our sample size, which could disproportionately affect a certain population or demographic when doing our analysis.\nWhen looking at the collection of data, “respect for persons” is very important. According to the data description, it seems that the HIV/AIDS data is collected through labs and doctors, not patients themselves. Given this, it is important for there to be some level of consent and awareness of this data collection practice by patients. As we mentioned before, re-identification is a risk when collecting such granular and sensitive data, so it is important to make patients aware and get their consent about these data-collecting practices.\n\n\nData Loading and Cleaning\nThe .rds file of our clean dataset was created successfully. The data was in a relatively clean state, with three revisions made so far. First, while the data from 2016-2021 has neighborhoods listed as well as the borough, the data from 2010-2013 only had the neighborhood, so the boroughs had to be filled in. We couldn’t use the fill function because the data wasn’t stored sequentially, so matching each neighborhood to a borough and filling in the boroughs in the csv file itself was the easiest way to do this. Second, all rows with any NA values were removed, using the complete.cases function from R’s documentation. Third, the dataset itself stored the Asian/Pacific Islander race in different ways, despite the spelling being the same in the csv file, using a line break instead of a space sometimes, which was fixed using a combination of str_replace_all and str_trim.\nBelow is some basic code for a boxplot of the total number of HIV diagnoses, grouped by race.\n\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(readr))\nsuppressPackageStartupMessages(library(here))\n\ndf &lt;- read_rds(here::here(\"dataset\", \"hiv_clean.rds\"))\n\nggplot(df, aes(x = `RACE/ETHNICITY`, y = `TOTAL NUMBER OF HIV DIAGNOSES`, fill = `RACE/ETHNICITY`)) +\n  geom_boxplot() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  \n  labs(title = \"Distribution of HIV Diagnoses by Race/Ethnicity\",\n       x = \"Race/Ethnicity\",\n       y = \"Total Number of HIV Diagnoses\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  ylim(0, 100)\n\nWarning: Removed 327 rows containing non-finite outside the scale range\n(`stat_boxplot()`).\n\n\n\n\n\n\n\n\n\nBelow is code for a bar chart, grouped by race.\n\nggplot(df, aes(x = reorder(`RACE/ETHNICITY`, -`TOTAL NUMBER OF HIV DIAGNOSES`), \n                        y = `TOTAL NUMBER OF HIV DIAGNOSES`, fill = `RACE/ETHNICITY`)) +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  labs(title = \"Total HIV Diagnoses by Race/Ethnicity\",\n       x = \"Race/Ethnicity\",\n       y = \"Total Number of HIV Diagnoses\") +\n  theme_minimal() +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nBased on these graphs, some trends noticed are higher levels of cases for Black and Hispanic people, compared to other races, despite lower populations, indicating potential underlying causes of this discrepancy. The “races” all, other/unknown, and unknown will be removed in further analysis."
  },
  {
    "objectID": "posts/2025-02-24-blog-post-1/blog-post-1.html",
    "href": "posts/2025-02-24-blog-post-1/blog-post-1.html",
    "title": "Blog Post 1",
    "section": "",
    "text": "Dataset 1: HIV/AIDS Diagnoses by Neighborhood, Sex, and Race/Ethnicity\nThis dataset consists of 8,976 rows and 11 columns, detailing various statistics on HIV and AIDS diagnoses in each borough of New York City and then each neighborhood in each borough from 2016 through 2020. This data is further grouped by race/ethnicity and sex. The data was reported to New York City’s Department of Health and Mental Hygiene and includes fields such as the number of HIV diagnoses, AIDS diagnoses, and their respective rates per 100,000 population, along with information on concurrent diagnoses and proportions.\nThe main aspects we wish to analyze are any trends in HIV/AIDS diagnoses over time, variations across neighborhoods and demographic groups, and the proportion of concurrent HIV/AIDS diagnoses. Challenges include dealing with missing or inconsistent data as well as cleaning the dataset.\n\n\nDataset 2: Health conditions among children under age 18, by selected characteristics: United States\nThis dataset contains 2,744 rows and 16 columns. The data focuses on health conditions among children under 18 years old in the United States, categorized by various characteristics, such as specific health conditions, age groups, and whether or not the child was insured. The data was collected through the National Health Interview Survey over many years, ranging from the late 1990s to the late 2010s.\nThe main questions to address include identifying trends in health conditions by race groups, how these conditions are distributed across various subcategories and the effect these additional variables have on those trends. The challenge will be to clean the dataset and condense information-dense columns, such as STUB_LABEL, into a format easier to read and work with in RStudio.\n\n\nDataset 3: Nutrition, Physical Activity, and Obesity - Women, Infant, and Child\nThis dataset contains 12,852 rows and 31 columns. The dataset includes information on children aged 3 months to 4 years old on their nutrition and obesity status, as well as information about the geographical location, demographics, health-related questions, race/ethnicity, age, and the year. The data was collected from Women, Infant, and Children Participant and Program Characteristics (WIC-PC).\nThrough working with this dataset, we will analyze any possible discrepancies in the nutrition and weight of young children across different races/ethnicities, as well the impact additional factors like location have on these potential discrepancies. A potential challenge we may face during the data cleaning process is how we can deal with the missing values regarding the low completeness of the demographic columns. Another challenge lies in the large amount of redundant information contained within this dataset. Much of the data does not directly contribute to addressing our main question, such as columns Class and Topic. It is necessary to establish an effective data filtering mechanism to quickly identify valuable information. We may also need to rearrange the dataset because the chronological order is messed up in this dataset."
  },
  {
    "objectID": "posts/2025-03-19-blog-post-3/blog-post-3.html",
    "href": "posts/2025-03-19-blog-post-3/blog-post-3.html",
    "title": "Blog post 3",
    "section": "",
    "text": "Since publishing blog post 2, we made a change to our cleaned dataset. In our .csv file, each row categorizes data by borough, neighborhood, race, gender, and year. Typically, there is one row for each category per year. For example, there is one row with data on white males who went to the hospital in Gramercy Park, Manhattan every year; however, in only 2020, this wasn’t the case. In 2020, there were two rows for each category, each with different numbers reported for our HIV/AIDS statistics. For example, only 2020 had two rows with data on white males who went to the hospital in Gramercy Park, Manhattan, and each row completely different data values. In order to aggregate the data in 2020 the same way it’s aggregated every other year, the separate rows were merged together. Because of this, our dataset has approximately 900 fewer rows, but no data’s lost. This was accomplished by going into the .csv file itself, creating a pivot table, and inserting the merged values into the dataset. This new .csv is available in the dataset folder, along with the original dataset, in case we deem it necessary to have the data aggregated that way for 2020 again. Since we see no reason to do so at the present time, our clean_data.R script was edited to use the .csv with the merged rows.\nFurther cleaning to the dataset was done as well. Similar to the issue with the way the race variable “Asian/Pacific Islander” was stored last blog post, all entries that had a space in the name, like Gramercy Park, were stored two different ways in the dataset, although invisible when looking at a table. Sometimes, the would be stored with a linebreak to create a space, instead of using the space bar. For the ease of looking at the names in a table, we removed the linebreaks and replaced them with spaces. We also added spaces to some names. For neighborhoods with “east side” or “west side” in their names, like Upper East Side, they were sometimes stored as “eastside” and “westside” in the dataset, without the space. We added spaces so they would match with the proper spelling of the neighborhoods.\nFinally, we made preliminary changes to our data page."
  },
  {
    "objectID": "posts/2025-04-07-blog-post-5/blog-post-5.html",
    "href": "posts/2025-04-07-blog-post-5/blog-post-5.html",
    "title": "Blog Post 5",
    "section": "",
    "text": "We are currently trying to merge census data with our dataset, to look for more predictors that might contribute to the different HIV/AIDS contractions dynamics we’ve already uncovered. It has been difficult to find datasets that can directly join with our dataset because of the way our original dataset is aggregated, using specific regions within New York City where there is a U.H.F. hospital, but we’ve found some datasets containing useful information that we may merge to further our analysis. Our current next step is to clean the datasets so that joining them with our original dataset can be done. Below are some of the datasets.\n\nPopulation\nThis link contains data on the population of each borough and neighborhood in New York City in 2024. However, the problem is that the division of neighborhoods in this dataset is somewhat different from our original dataset.\n\n\nPrison\nThis link contains population data for neighborhoods that are largely the same as those in our original dataset. However, the problem is that the website does not provide a downloadable dataset.\n\n\nPlanning\nThis link contains more complete data on each neighborhood, including population size, ethnicity, and age. However, we have encountered some problems. First, our original dataset contains a column for neighborhoods. Unfortunately, most census datasets do not base their surveys on neighborhoods. This means that it is difficult for us to directly merge the census dataset into the original dataset. In addition, among the limited data on neighborhoods, the criteria for dividing the boundaries of many neighborhoods are different. New York City has several different sets of rules for defining neighborhoods, such as NTA (Neighborhood Tabulation Areas) and U.H.F (United Hospital Fund Neighborhood). Our original dataset uses U.H.F. This further limits our ability to find a dataset that we can use directly. For the census data, our next step is to see if we can transfer the Neighborhood information from other datasets to our original dataset by defining the boundaries of Neighborhood in our original dataset. If this is difficult to achieve, we may give up Neighborhood and directly merge the data based on borough.\n\n\nEnvironment and Health Data\nThis link is to New York City’s official Environment and Health Data portal. On that website, New York City’s government publishes datasets collected by the American Community Survey on various topics, such as neighborhood poverty, unemployment, and health insurance rates. The particular link above links to neighborhood poverty, but a dataset containing data on the aforementioned categories can be accessed by clicking on the corresponding header on the left side of the page, under the “Datasets” header. Below that, there are datasets on housing and social conditions, such as race, incarceration, and education level. .csv files of every dataset can be downloaded."
  },
  {
    "objectID": "posts/2025-04-22-blog-post-7/blog-post-7.html",
    "href": "posts/2025-04-22-blog-post-7/blog-post-7.html",
    "title": "Blog Post 7",
    "section": "",
    "text": "For this blog post, we created a basic form of our interactive. This interactive component allows users to explore HIV/AIDS-related data across New York City by borough and neighborhood. Users can filter the data by year, sex, and race/ethnicity through intuitive drop-down menus, making it easy to examine disparities across different demographic groups and time periods. Additionally, users can toggle between different metrics, such as HIV diagnoses rate and AIDS diagnoses rate, to gain a more comprehensive understanding of how these factors intersect. This component is highly effective because it presents complex public health data in a visually engaging and geographically contextualized manner, enabling deeper insight into spatial and demographic patterns of health inequality in NYC.\nYou can explore the interactive map at the link below: Click here to open the Interactive Map Explorer"
  },
  {
    "objectID": "dataset/NYC_EH_Data_Portal_Health_Insurance.html",
    "href": "dataset/NYC_EH_Data_Portal_Health_Insurance.html",
    "title": "NYC_EH_Data_Portal_Health_Insurance",
    "section": "",
    "text": "library(readr)\nnyc_health_insurance &lt;- read_csv(\"dataset/NYC EH Data Portal - Health insurance (adults) (filtered)(1).csv\")\n\nRows: 320 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): GeoTypeDesc, BoroID, Borough, Geography, Area, Number, Percent\ndbl (3): TimePeriod, GeoID, GeoRank\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nnyc_health_insurance \n\n# A tibble: 320 × 10\n   TimePeriod GeoTypeDesc GeoID GeoRank BoroID Borough    Geography Area  Number\n        &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;      &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; \n 1       2021 Citywide        1       0 -      -          New York… New … 5,610…\n 2       2021 Borough         1       1 1      Bronx      Bronx     Bronx 852,0…\n 3       2021 Borough         2       1 2      Brooklyn   Brooklyn  Broo… 1,717…\n 4       2021 Borough         3       1 3      Manhattan  Manhattan Manh… 1,197…\n 5       2021 Borough         4       1 4      Queens     Queens    Quee… 1,520…\n 6       2021 Borough         5       1 5      Staten Is… Staten I… Stat… 325,0…\n 7       2021 UHF 34        101       3 1      Bronx      Kingsbri… King… 58,000\n 8       2021 UHF 34        102       3 1      Bronx      Northeas… Nort… 137,0…\n 9       2021 UHF 34        103       3 1      Bronx      Fordham … Ford… 156,0…\n10       2021 UHF 34        104       3 1      Bronx      Pelham -… Pelh… 184,0…\n# ℹ 310 more rows\n# ℹ 1 more variable: Percent &lt;chr&gt;\n\nhiv_clean &lt;- read_rds(\"https://sussmanbu.github.io/ma4615-sp25-final-project-team-5/dataset_for_shiny/hiv_clean.rds\")\n\n#nyc_health_insurance |&gt; distinct(Geography)"
  },
  {
    "objectID": "dataset/insurance_maps_by_year.html",
    "href": "dataset/insurance_maps_by_year.html",
    "title": "insurance_maps_by_year",
    "section": "",
    "text": "suppressPackageStartupMessages(library(sf))\nsuppressPackageStartupMessages(library(tidyverse))\nsuppressPackageStartupMessages(library(readr))\nsuppressPackageStartupMessages(library(here))\nlibrary(leaflet)\n\nshape &lt;- st_read(here::here(\"dataset\", \"NYC_geography-master\", \"NYC_geography-master\", \"uhf34_shapefiles\", \"CHS_UHF_34_DOHMH_2004.shp\"), quiet = TRUE)\n\nshape &lt;- shape |&gt; rename(GeoID=UHFtxt) |&gt; select(GeoID) |&gt; filter(GeoID!=0)\n\n\n\ninsurance &lt;- read_csv(here::here(\"dataset\", \"NYC EH Data Portal - Health insurance (adults) (filtered)(1).csv\"),\n                 col_types = cols(GeoID = col_character()))\n\ninsurance &lt;- insurance |&gt; mutate(percent_only = str_extract(Percent, \"^[0-9.]+\"))\n\ninsurance_uhf &lt;- insurance |&gt; filter(!(Geography %in% c(\"New York City\", \"Bronx\", \"Brooklyn\", \"Manhattan\", \"Queens\", \"Staten Island\")))\n\n##################################################################################################\n\ninsurance_uhf_filter_2021&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2021\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2020&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2020\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2019&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2019\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2018&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2018\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2017&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2017\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2016&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2016\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2013&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2013\")|&gt;select(GeoID, percent_only)\n\ninsurance_uhf_filter_2012&lt;-insurance_uhf |&gt; filter(TimePeriod==\"2012\")|&gt;select(GeoID, percent_only)\n\n##################################################################################################\n\njoined_2021 &lt;- shape |&gt; left_join(insurance_uhf_filter_2021, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2020 &lt;- shape |&gt; left_join(insurance_uhf_filter_2020, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2019 &lt;- shape |&gt; left_join(insurance_uhf_filter_2019, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2018 &lt;- shape |&gt; left_join(insurance_uhf_filter_2018, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2017 &lt;- shape |&gt; left_join(insurance_uhf_filter_2017, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2016 &lt;- shape |&gt; left_join(insurance_uhf_filter_2016, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2013 &lt;- shape |&gt; left_join(insurance_uhf_filter_2012, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\njoined_2012 &lt;- shape |&gt; left_join(insurance_uhf_filter_2012, by = \"GeoID\") |&gt; mutate(percent_only = as.double(percent_only))\n\n##################################################################################################\n\nall_data &lt;- bind_rows(\n  joined_2021,\n  joined_2020,\n  joined_2019,\n  joined_2018,\n  joined_2017,\n  joined_2016,\n  joined_2013,\n  joined_2012\n)\n\n##################################################################################################\n\n# Global min and max for color scale\nglobal_min &lt;- min(all_data$percent_only, na.rm = TRUE)\nglobal_max &lt;- max(all_data$percent_only, na.rm = TRUE)\n\n##################################################################################################\n\nggplot() +\n  geom_sf(data = joined_2021, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2021\")\n\n\n\n\n\n\n\nggplot() +\n  geom_sf(data = joined_2020, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2020\")\n\n\n\n\n\n\n\nggplot() +\n  geom_sf(data = joined_2019, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2019\")\n\n\n\n\n\n\n\nggplot() +\n  geom_sf(data = joined_2018, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2018\")\n\n\n\n\n\n\n\nggplot() +\n  geom_sf(data = joined_2017, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2017\")\n\n\n\n\n\n\n\nggplot() +\n  geom_sf(data = joined_2016, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2016\")\n\n\n\n\n\n\n\nggplot() +\n  geom_sf(data = joined_2013, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2013\")\n\n\n\n\n\n\n\nggplot() +\n  geom_sf(data = joined_2012, aes(fill = percent_only), alpha = 0.8) +\n  scale_fill_viridis_c(option = \"D\", limits = c(global_min, global_max)) +\n  labs(title = \"2012\")\n\n\n\n\n\n\n\n\n\nlibrary(sf)\nlibrary(readr)\nlibrary(here)\n\nshape_uhf34 &lt;- st_read(here::here(\"dataset\", \"NYC_geography-master\", \"NYC_geography-master\", \"uhf34_shapefiles\", \"CHS_UHF_34_DOHMH_2004.shp\"), quiet = TRUE)\nshape_uhf42 &lt;- st_read(here::here(\"dataset\", \"NYC_geography-master\", \"NYC_geography-master\", \"uhf42_shapefiles\", \"UHF42.shp\"), quiet = TRUE)\n\nst_crs(shape_uhf34)\nst_geometry(shape_uhf34)\n\nshape_uhf34_setcrs &lt;- st_set_crs(shape_uhf34, 2263)\n\nuhf34_setcrs &lt;- st_transform(shape_uhf34_setcrs, st_crs(shape_uhf42))\n\n\nuhf34_setcrs\n\n\nlibrary(ggplot2)\n\nggplot() +\n  geom_sf(data = uhf42_setcrs, fill = NA, color = \"blue\", size = 1) +  # UHF42 in blue\n  geom_sf(data = uhf34_setcrs, fill = NA, color = \"red\", size = 0.5, linetype = \"dashed\") +  # UHF34 in red dashed\n  labs(title = \"Comparison of UHF42 (Blue) and UHF34 (Red Dashed) Neighborhoods\") +\n  theme_minimal() \n\n# + geom_sf_label(data = uhf34_setcrs, aes(label = UHF_NAME))\n\n\n# uhf42_latlon &lt;- st_transform(uhf42_setcrs, 4326)\n# uhf34_latlon &lt;- st_transform(uhf34_setcrs, 4326)\n# \n# leaflet() |&gt;\n#   addTiles() |&gt;\n#   addPolygons(data = uhf42_latlon, color = \"blue\", weight = 2, fillOpacity = 0.2, group = \"UHF42\") |&gt;\n#   addPolygons(data = uhf34_latlon, color = \"red\", weight = 1, fillOpacity = 0.2, group = \"UHF34\") |&gt;\n#   addLayersControl(overlayGroups = c(\"UHF42\", \"UHF34\"),\n#                    options = layersControlOptions(collapsed = FALSE))"
  },
  {
    "objectID": "big_picture.html",
    "href": "big_picture.html",
    "title": "An Unequal Epidemic: How HIV Hits NYC Communities Differently",
    "section": "",
    "text": "Overview\nIn New York City, HIV and AIDS have been public health concerns for decades. But not all New Yorkers face the same level of risk. Our analysis reveals a troubling reality: your race, gender, and where you live can dramatically affect your likelihood of being diagnosed with HIV or AIDS. Specifically, Black residents experience a disproportionately high burden of HIV and AIDS, compared to their counterparts. Through accessible visuals and an interactive map, we show how these disparities play out across the five boroughs — and why it matters.\n\n\nVisualizing Disparities\n\nDisparity by Race and Sex\nThe first thing someone might expect to read about when analyzing HIV and AIDS cases is how many cases there are. To start, we plotted the total number of HIV and AIDS cases per borough.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe also plotted these totals for each race.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn these plots, two aspects stand out. In both total HIV and AIDS cases, the Bronx and Brooklyn are at the top for boroughs and Black and Hispanic are at the top for races. But since these are total counts, they don’t factor in population differences. It’s possible these boroughs and races are only at the top because they have the largest populations. In order to account for this, we plotted the average number of HIV cases per 100,000 people per borough and race. Plotting by per 100,000 people rates normalizes the population to be 100,000 people for each area, so areas with higher populations aren’t punished.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs seen above, population did factor into the higher totals for the boroughs. Brooklyn had the most total HIV diagnoses and the second most total AIDS cases, but is third in both categories when normalizing for population, suggesting Brooklyn’s larger population contributed to its higher rankings. Manhattan went from third in total HIV and AIDS cases to second in terms of rates per 100,000, suggesting its lower total is due to it having a smaller population, which potentially masked socioeconomic inequities causing its increased contraction rates.\nPopulation didn’t have a significant impact on the races, however. Black people had the most total cases for both HIV and AIDS, and had the largest rate of cases per 100,000 too, suggesting their higher rates aren’t just due to population, but other factors. Hispanic people were also second in totals for both and remained second in per 100,000 rates, suggesting their placement wasn’t solely due to population either.\nEach borough in New York City is split into several different neighborhoods by New York City’s DOHMH, totaling to 42 different neighborhoods, called the UHF42 neighborhoods. Below we plotted the HIV and AIDS totals for each neighborhood, to see which neighborhoods were contributing the most cases to their respective borough’s total.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs expected, the neighborhoods at the top are mostly in Brooklyn, the Bronx, and Manhattan, although West Queens is an outlier. As already discovered, Black and Hispanic people had the highest totals and rates of HIV. Now that we see which neighborhoods have the most cases, does it hold that those neighborhoods generally have the highest proportions of Black and Hispanic residents? Below are two maps of New York City, broken up into its UHF42 neighborhoods. The first plot colors each neighborhood by its Black proportion and the second colors each by its Hispanic proportion.\n\n\nLinking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.1; sf_use_s2() is TRUE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs seen in the above plots, the assumption that the neighborhoods with the highest totals and rates of HIV and AIDS also have the highest proportion of Black and Hispanic residents checks out. Manhattan (the most northwestern area), the Bronx (the most northeastern area), and Brooklyn (the most southeastern area of the mainland) have the most Black and Hispanic residents. Queens and Staten Island have the least Black and Hispanic residents, matching their lower totals and rates. Although, the West Queens outlier from before does have a relatively high proportion of Hispanic people, which could explain why they had so many cases.\n\n\nGender-Based Disparities\nAcross all racial groups, males consistently showed higher diagnosis rates than females—especially pronounced among Asian/Pacific Islanders.This chart highlights a striking gender disparity in the average rate of AIDS diagnoses per 100,000 people in New York City. The data shows that males are diagnosed with AIDS at more than double the rate of females, with an average of about 25 per 100,000 compared to less than 10 for females. This pattern holds across multiple racial and geographic groups and has persisted over time. The reasons behind this disparity are complex and may include differences in risk behaviors, testing frequency, social stigma, or access to early HIV treatment, which can prevent the progression to AIDS. This gap underscores the need for gender-specific public health interventions, especially outreach, education, and prevention programs targeted at high-risk male populations.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive\nTo make the patterns in our data more accessible and meaningful, we created an interactive map of New York City that allows users to explore HIV and AIDS diagnosis rates by neighborhood. This tool provides a dynamic way to visualize disparities by year, sex, race/ethnicity, and type of diagnosis (HIV vs. AIDS). With just a few clicks, you can see how certain neighborhoods — particularly in the Bronx, Brooklyn, and parts of Manhattan — consistently report higher diagnosis rates. You can also observe how specific demographic groups are impacted differently depending on location. For instance, selecting “Asian/Pacific Islander” and “Male” reveals neighborhoods where HIV rates are unexpectedly high for that group, reinforcing one of our key findings. This map empowers users to interact with the data in real time, uncovering patterns that might be missed in static charts. Ultimately, it reinforces our central message: the HIV/AIDS epidemic in NYC is deeply shaped by geography, race, and gender — and our response must be just as specific and targeted.\nYou can explore the interactive map at the link below: Click here to open the Interactive Map Explorer\n\n\nConclusion\nOur analysis makes one thing clear: HIV and AIDS do not affect all New Yorkers equally. The burden of this epidemic falls disproportionately on Black and Hispanic communities, men, and residents of underserved boroughs like Brooklyn and the Bronx. While overall diagnosis rates have declined in recent years, the story is far from one of universal progress. Rising rates among Asian/Pacific Islander males and persistent disparities across neighborhoods show that public health improvements have not been evenly distributed. This isn’t just a health issue — it’s a reflection of deeper structural inequalities in healthcare access, education, income, and stigma. The HIV/AIDS epidemic in NYC is a mirror of the city’s broader social landscape, revealing who is most likely to be overlooked or left behind. Looking ahead, such data should not merely serve as a record, but rather as a call to action. Public health strategies must be precise, inclusive, and equity-oriented to ensure that prevention, testing, and care services truly benefit the people and regions that need them most."
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "This comes from the file data.qmd."
  },
  {
    "objectID": "data.html#data-overview",
    "href": "data.html#data-overview",
    "title": "Data",
    "section": "Data Overview",
    "text": "Data Overview\n\nMain Dataset\nOur primary dataset is HIV/AIDS Diagnoses by Neighborhood, Sex, and Race/Ethnicity. The data was originally collected from the New York City Department of Health and Mental Hygiene (NYC DOHMH), which collected and compiled information on new HIV and AIDS diagnoses reported through March 31, 2021. Specifically, this dataset covers cases diagnosed from calendar years 2010 through 2013, then 2016 through 2020. The data were collected to monitor trends in HIV and AIDS diagnoses, enabling public health officials to track disease patterns, guide prevention and treatment strategies, and identify disparities across different neighborhoods and demographic groups within NYC. Cases are stratified by borough, United Hospital Fund (UHF) neighborhoods, sex, and race/ethnicity, allowing for targeted public health responses. For each category, the dataset tracks the total number of HIV and AIDS cases and the case rate per 100,000 people. The original dataset can be obtained directly from the NYC DOHMH or accessed through official public health data portals maintained by New York City. Below is a list of the variables in the dataset.\n\n\n\n\n\n\n\n\nVariable Descriptions\n\n\nVariable\nData_Types\nDescription\n\n\n\n\nYEAR\nnumeric\nThe year\n\n\nBorough\ncharacter\nWhich borough in New York City the data is from\n\n\nNeighborhood (U.H.F)\ncharacter\nWhich UHF42 neighborhood the data is from\n\n\nSEX\ncharacter\nWhich sex is the data applies to\n\n\nRACE/ETHNICITY\ncharacter\nWhich race/ethnicity the data applies to\n\n\nTOTAL NUMBER OF HIV DIAGNOSES\nnumeric\nNumber of people diagnosed with HIV in the given area, during that year\n\n\nHIV DIAGNOSES PER 100,000 POPULATION\nnumeric\nThe predicted number of HIV diagnoses in an area, in a given year, per 100,000 people\n\n\nTOTAL NUMBER OF CONCURRENT HIV/AIDS DIAGNOSES\nnumeric\nThe number of people diagnosed with HIV and AIDS concurrently\n\n\nPROPORTION OF CONCURRENT HIV/AIDS DIAGNOSES AMONG ALL HIV DIAGNOSES\nnumeric\nWhat proportion of all new HIV diagnoses in an area, during that year, are concurrent HIV/AIDS diagnoses\n\n\nTOTAL NUMBER OF AIDS DIAGNOSES\nnumeric\nThe number of people diagnosed with AIDS in an area, during that year\n\n\nAIDS DIAGNOSES PER 100,000 POPULATION\nnumeric\nThe predicted number of AIDS diagnoses in an area, in a given year, per 100,000 people\n\n\n\n\n\n\n\nThis analysis primarily focuses on the TOTAL NUMBER OF CONCURRENT HIV/AIDS DIAGNOSES column. The main reasons for this are:\n\nSince HIV, when untreated, progresses to AIDS, it reflects a late diagnosis. Since this analysis investigates potentially inequality in testing to do a lack of resources or other structural barriers, these diagnoses are directly linked to that phenomenon.\nConcurrent diagnoses are more sensitive to neighborhood-level inequality because late testing is often influenced by: distrust in local healthcare, overburdened clinics, a lack of insurance, and stigma.\nThese diagnoses are in the most urgent need of assistance.\n\nBelow is a histogram displaying the values TOTAL NUMBER OF CONCURRENT HIV/AIDS DIAGNOSES tends to take when filtered by individual neighborhood and including all races and sexes.\n\n\n\n\n\n\n\n\n\nThe histogram displays a clear right-skewed distribution. Most of the values seems to be concentrated in the 0-5 case range, which makes sense, since being diagnosed with HIV and AIDS concurrently is rarer than just HIV or just AIDS. Although, there are still a significant number of cases in the 10-25 case range, demonstrating this is still an issue affecting a significant number of people. There are a few instances of the case numbers surpassing 40 and even 50, indicating some outlier neighborhoods which experience extreme burdens.\n\n\nSecondary Datasets\nThe other datasets we used came from the same source, which is nyc.gov’s Environment and Health Data Portal. This website is run by New York City’s Department of Health and Mental Hygiene and is where their employees store data they accumulate about New York City’s public health, in order for decision makers and regular citizens to observe trends within the city. This link is to a dataset calculating the proportion of each race in each borough and UHF neighborhood, although that is only one of the many social conditions they monitor. Other conditions monitored include: high school graduation rates, unemployment rates, incarceration rates, and health insurance rates. Each of these datasets is on one specific topic which you select, and for that topic, it will display the proportion of that borough which meets the criteria, for every year they calculated the data. For the race dataset, for each year, it will list the proportion of each major race in each borough, and then each UHF neighborhood within that borough. Because the website is run by the same people who collected our primary dataset, they use the same storage system with race and sex within each borough and UHF neighborhood, making joining datasets easier. Additionally, each dataset, when downloaded, although not visible on the website, comes with each neighborhood’s GEOID, allowing it to be combined with census shapefiles for visualization. Below is a list of all variables added to the main dataset to be used as predictors.\n\n\n\n\n\n\n\n\nVariable Descriptions\n\n\nVariable\nData_Type\nDescription\n\n\n\n\nEstimated Poverty Rate\nnumber\nPercentage of people in that neighborhood, in that year, which live below the poverty line\n\n\nasian_prop\nnumber\nProportion of Asian residents in that neighborhood, in that year\n\n\nblack_prop\nnumber\nProportion of black residents in that neighborhood, in that year\n\n\nhispanic_prop\nnumber\nProportion of Hispanic residents in that neighborhood, in that year\n\n\nwhite_prop\nnumber\nProportion of white residents in that neighborhood, in that year\n\n\nEstimated Non-High School Graduation Rate\nnumber\nPercentage of people living in that neighborhood, ages 25 and up, in that year, who did not graduate high school\n\n\nEstimated Unemployment Rate\nnumber\nPercentage of people ages 16 and up, living in that neighborhood, in that year, who are unemployed\n\n\nEstimated Rent-Burdened Household Rate\nnumber\nPercentage of people in that neighborhood, in that year, who spend 30% or more of their income on rent and utilities\n\n\nEstimated Non-Owner-Occupied Home Rate\nnumber\nPercentage of people in that neighborhood, in that year, who live in homes they do not own\n\n\nEstimated Child Poverty Rate\nnumber\nPercentage of children under five years old in that neighborhood, in that year, living below the poverty line\n\n\nEstimated Asthma Hospitalization Rate\nnumber\nNumber of asthma cases per 10,000 which requires hospitalization per neighborhood, per year\n\n\nEstimated Crowded Household Rate\nnumber\nPercentage of households in that neighborhood, in that year, which have more than one person per room living in it\n\n\nEstimated Non-Health Insurance Rate\nnumber\nPercentage of people in that neighborhood, in that year, which do not have health insurance\n\n\n\n\n\n\n\nBelow are some quick graphs of some variables. First, a histogram displaying the values black_prop tends to take on.\n\n\n\n\n\n\n\n\n\nThe graph has a right-skewed distribution, indicating many UHF42 neighborhoods are not racially homogeneous. Most neighborhoods seem to be anywhere from 2-8% black. Despite that, there are some neighborhoods which are over 60% black, indicating certain races tend to live together in the same neighborhoods.\nNext, a plot displaying the values Estimated Non-Health Insurance Rate tends to take on.\n\n\n\n\n\n\n\n\n\nThis graph displays a more normal distribution than other variables, but still slightly skewed to the right. Most neighborhoods have around 6-16% of their residents uninsured, which makes sense, as with Medicare and Medicaid being available, most people qualify for some sort of health insurance, although that doesn’t prevent outliers, such as one neighborhood with nearly 50% of its residents having no health insurance, potentially indicating extreme underfunding and a lack of attention.\nFinally, below is a graph displaying the values Estimated Poverty Rate tends to take on.\n\n\n\n\n\n\n\n\n\nThis graph also displays a right-skewed distribution. Most neighborhoods have around 5-15% of their residents living in poverty, although there are a significant number of times when a neighborhood has 20% or more of its residents living in poverty, with some outliers each surpassing 40%, continuing to indicate some extreme outliers in the data and neighborhoods which may be underfunded and underrepresented.\nThe shapefiles we used can be found on New York City’s Environmental Health Services Team’s public GitHub. Specifically, this repository contains the UHF 42 .shp files and .json files we used in our maps and our interactive."
  },
  {
    "objectID": "data.html#cleaning-the-data",
    "href": "data.html#cleaning-the-data",
    "title": "Data",
    "section": "Cleaning the Data",
    "text": "Cleaning the Data\nHere is the link to our clean_data.R script. This cleaning was done on the main HIV/AIDS dataset.\nThe first step in cleaning the dataset was filling in missing borough values for data compiled from 2010-13. The original dataset always compiled the neighborhood, but didn’t start including the borough until 2016. Because of the data not being stored according to borough, but having neighborhoods from different boroughs stored in neighboring cells, the fill command couldn’t be used because it would take the last borough value and fill that in for all missing borough values, which would attribute that borough to incorrect neighborhoods. Instead, we made a copy of the original dataset and used a command within a Microsoft Excel spreadsheet to assign each neighborhood the proper borough and then pasted that command into each blank borough cell and had the spreadsheet fill in the missing values.\nNext, we ensured all variables were stored the same way. In the original dataset, the authors sometimes compiled the same variable in different ways. One of the most common disparities was in how variables with a space in the name were stored. Sometimes, instead of using a space, the authors used a line break. When viewing these names in the .csv file or in an imported dataset in R, the difference was invisible, but when trying to perform analysis, R would consider these variables with the same name to be two different variables, due to the line break. In order to fix this, all line breaks were replaced with spaces, which can be seen in our clean_data.R script. Below is a quick example of what a line of code for adjusting one variable name looks like.\nRACE/ETHNICITY = str_replace_all(RACE/ETHNICITY, “”, ” “)\nThere were other ways a slightly different spelling made R consider a variable referring to the same place or race as two different variables. Sometimes, it was due to the lack of a space where there sometimes was a space, as in the neighborhood Upper East Side. In the original dataset, sometimes this was stored as “Upper Eastside.” We added a space to variables stored like this, in order for the variable names to coincide with the actual names of the neighborhoods. Another storage difference was with the Hispanic race variable. Sometimes it was stored as “Latino/Hispanic” and other times as just “Hispanic”; we stored every instance of it as “Hispanic” for simplicity. A list of all changes to variable names of this manner can be seen in our clean_data.R script. Below is an example of what this looks like for one name.\nRACE/ETHNICITY = str_replace_all(RACE/ETHNICITY, “Latino/Hispanic”, “Hispanic”)\nFinally, we used the complete.cases function to filter out all rows with NA values.\nA similar process was done for the secondary datasets we added. Often, they would store the same UHF 42 neighborhood name differently than the main dataset. For example, they would often store the neighborhood “Fordham - Bronx Park” as “Fordham - Bronx Pk”. Using the same process above, this was changed for all names stored in this way, so the datasets could be joined easier. Joining the datasets occured by doing a simple left_join with the main dataset and joining by YEAR and Neighborhood (U.H.F). The secondary datasets would then add one column with the predictor value they added, such as poverty rate.\nThe last major cleaning step done to get our data was extract single-year values from the secondary datasets. Despite being compiled by the same people who compiled our original dataset, the secondary datasets were often compiled in five-year increments and the assigned values would be the average over that five year period. The HIV dataset was compiled on a year-to-year basis, so assigning the five-year averages to a single year wasn’t plausible. This was the compromise:\n\nEach five-year period would have its midyear calculated. For example, for the period 2017-2021, the midyear is 2019.\nThe five-year averages would be assigned to the midyear.\nBased on the years the authors compiled, this gave us data for all the years in our original dataset, except 2020 and 2021.\nUsing the averages now assigned to the midyears, a polynomial model was constructed which predicted the values of each variable for 2020 and 2021 and created a tibble containing an estimated rate of each variable in each UHF42 neighborhood, in each year. Below is an example of this process being done for the Estimated Unemployment Rate variable and the resulting table below, filtered to show what it looks like for one neighborhood. This process was repeated for each predictor variable.\n\n\nunemp &lt;- read_csv(\n  here::here(\"dataset\", \"NYC EH Data Portal - Unemployment (filtered).csv\"),\n  show_col_types = FALSE)\n\nunemp_f &lt;- unemp |&gt;\n  mutate(midpoint = as.integer(str_extract(TimePeriod, \"\\\\d{4}\")) + 2)\n\nunemp_by_neighborhood &lt;- unemp_f |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(Percent ~ poly(midpoint, 2), data = .x)),\n    newdata = list(tibble(midpoint = 2007:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate = \n                                          predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!midpoint %in% c(2007, 2008, 2009, 2014, 2015)) |&gt;\n  rename(\n    YEAR = midpoint,\n    `Neighborhood (U.H.F)` = Geography,\n    `Estimated Unemployment Rate` = estimated_rate\n  ) |&gt;\n  mutate(\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`,\n                             \"Upper East Side\", \"Upper Eastside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \n                               \"Upper West Side\", \"Upper Westside\"),\n    `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \n            \"Greenwich Village - SoHo\", \"Greenwich Village - Soho\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`, \n                            \"Crotona -Tremont\", \"Crotona - Tremont\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`,\n                                         \"Rockaways\", \"Rockaway\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`,\n                    \"Fordham - Bronx Pk\", \"Fordham - Bronx Park\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`,\n   \"Downtown - Heights - Slope\", \"Downtown - Heights - Park Slope\"),\n  `Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`,\n            \"Washington Heights\", \"Washington Heights - Inwood\")\n  )\n\nsuppressPackageStartupMessages(library(rmarkdown))\nknitr::kable(head(unemp_by_neighborhood, 10))\n\n\n\n\nNeighborhood (U.H.F)\nYEAR\nEstimated Unemployment Rate\n\n\n\n\nKingsbridge - Riverdale\n2010\n9.788671\n\n\nKingsbridge - Riverdale\n2011\n9.640979\n\n\nKingsbridge - Riverdale\n2012\n9.442238\n\n\nKingsbridge - Riverdale\n2013\n9.192448\n\n\nKingsbridge - Riverdale\n2016\n8.136783\n\n\nKingsbridge - Riverdale\n2017\n7.682797\n\n\nKingsbridge - Riverdale\n2018\n7.177762\n\n\nKingsbridge - Riverdale\n2019\n6.621678\n\n\nKingsbridge - Riverdale\n2020\n6.014545\n\n\nKingsbridge - Riverdale\n2021\n5.356364\n\n\n\n\n\nBecause most of the predictor variables were risk factors, some variables which weren’t risk factors, like high school graduation rate, were turned into risk factors by using that rate to calculate the proportion of people which did not graduate high school. This was done because it was expected that if more people graduated high school, they would have a higher level of education and therefore know more about health and safety measures, so a higher value was beneficial. This seemed like an awkward pairing with other variables, like poverty rate, where a higher value was worse than a lower value. The opposite of each seemingly beneficial predictor was calculated for these purposes. This was done for: Estimated Non-High School Graduation Rate, Estimated Non-Owner-Occupied Home Rate and Estimated Non-Health Insurance Rate. The calculation was very simple. Using the process described above gave the proportion of people who did do these things, for example, the proportion of people who graduated high school. To find the proportion of people who didn’t graduate high school, all that had to be done is do 1 - proportion of people who graduated high school.\nThe only predictor variable which required another extra step was Estimated Non-Health Insurance Rate. This is because the data was stored according to UHF34 neighborhoods, instead of UHF42 neighborhoods like the original dataset and the rest of the predictors. New York City’s DOHMH sometimes stored data in UHF34 neighborhoods in order to get more people in each neighborhood. They formed these UHF34 neighborhoods by combing some smaller UHF42 neighborhoods into one neighborhood. Most UHF34 neighborhoods are the same as their UHF42 neighborhood.\nBelow are two maps: the first displays New York City broken up into UHF42 neighborhoods, and the second displays New York City broken up into UHF34 neighborhoods.\n\n\nLinking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.1; sf_use_s2() is TRUE\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAs displayed above, Staten Island had its four UHF42 neighborhoods combined into two UHF34 neighborhoods. Manhattan (the most northwestern area) had several small UHF42 neighborhoods condensed, as well as the Bronx (the most northeastern area).\nThe way we settled on adding health insurance as a predictor was to map each UHF42 neighborhood to the UHF34 neighborhood it belongs to and then assign the value associated with that UHF34 neighborhood to each UHF42 neighborhood in that neighborhood. This had the downside of only adding 34 unique values, instead of 42, which reduced the integrity of our model, but health insurance was thought to be a valuable enough predictor to do so.\nBelow is the entire process through which this was accomplished.\n\nhi &lt;- read_csv(\n  here::here(\"dataset\",\n  \"NYC EH Data Portal - Health insurance (adults) (filtered)(1).csv\"),\n  show_col_types = FALSE)\n\nmap_uhf &lt;- read_csv(\n  here::here(\"dataset\", \"UHF34_to_UHF42 .csv\"), show_col_types = FALSE) |&gt;\n  mutate(`Neighborhood (U.H.F)` = str_replace_all(`Neighborhood (U.H.F)`,\n                        \"Staple - St. George\", \"Stapleton - St. George\"))\n\nhi_f &lt;- hi |&gt;\n  filter(GeoTypeDesc == \"UHF 34\") |&gt;\n  rename(YEAR = TimePeriod) |&gt;\n  select(YEAR, GeoTypeDesc, Geography, Percent) |&gt;\n  mutate(\n    Percent = str_remove_all(Percent, \"\\\\*|\\\\s*\\\\(.*\\\\)\"),\n    Percent = as.numeric(Percent)\n  ) |&gt;\n  group_by(Geography) |&gt;\n  nest() |&gt;\n  mutate(\n    model = map(data, ~ lm(`Percent` ~ poly(YEAR, 2), data = .x)),\n    newdata = list(tibble(YEAR = 2010:2021)),\n    predicted = map2(model, newdata, ~ mutate(.y, estimated_rate =\n                                        predict(.x, newdata = .y)))\n  ) |&gt;\n  select(Geography, predicted) |&gt;\n  unnest(predicted) |&gt;\n  filter(!YEAR %in% c(2014, 2015)) |&gt;\n  mutate(`Estimated Non-Health Insurance Rate` = 100 - `estimated_rate`) |&gt;\n  select(-`estimated_rate`)\n\nsuppressWarnings({\nhi_uhf &lt;- hi_f |&gt;\n  left_join(map_uhf, by = \"Geography\") |&gt;\n  ungroup() |&gt;\n  select(-Geography)\n})\n\nmap_uhf is a .csv created created ourselves, which maps each UHF42 neighborhood to its UHF34 neighborhood."
  }
]